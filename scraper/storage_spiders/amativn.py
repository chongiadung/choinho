# Auto generated by generator.py. Delete this line if you make modification.
from scrapy.spiders import Rule
from scrapy.linkextractors import LinkExtractor

XPATH = {
    'name' : "//div[@id='content']/h1",
    'price' : "//div[@class='price']/a",
    'category' : "//div[@class='breadcrumb']/a[2]",
    'description' : "//div[@id='tab-description'] | //div[@id='tab-description']/p/img/@src",
    'images' : "//div[@class='zoomPad']/img/@src",
    'canonical' : "",
    'base_url' : "",
    'brand' : ""
}
name = 'amati.vn'
allowed_domains = ['amati.vn']
start_urls = ['http://amati.vn']
tracking_url = ''
sitemap_urls = ['']
sitemap_rules = [('', 'parse_item')]
sitemap_follow = []
rules = [
    Rule(LinkExtractor(deny=['dang-nhap', 'create-account', 'trang-chu', 'google', 'facebook', 'gioi-thieu', 'lien-he', 'request-return', 'sitemap', 'hang-san-xuat', 'laptopcu247', 'index', 'dieukhacdamynghe', 'tin-tuc', 'specials', 'affiliates', 'quan-tam', 'order-history', 'tai-khoan-khach-hang' , 'newsletter' ]), 'parse_item'),
    Rule(LinkExtractor(allow=['/$']), 'parse'),
    #Rule(LinkExtractor(), 'parse_item_and_links'),
]
