# Auto generated by generator.py. Delete this line if you make modification.
from scrapy.spiders import Rule
from scrapy.linkextractors import LinkExtractor

XPATH = {
    'name' : "//div[@class='info']/div[@class='left_info']/div[@class='block']/h1|//div[@class='block']/h1[@class='name_change']",
    'price' : "//div[@class='block form']/div[@class='price_show']/div[@class='link']/strong[@class='new-price cam']|//div[@class='link']/strong[@class='new-price cam']|//div[@class='link']/strong[@class='new-price red_price']",
    'category' : "",
    'description' : "//div[@class='tabscontent']/div[@class='check-detail ']",
    'images' : "//ul[@id='thumbs_list_frame']/li/a/@href|//div[@class='image no_border_bottom']//div/img/@src",
    'canonical' : "//link[@rel='canonical']/@href",
    'base_url' : "",
    'brand' : ""
}
name = 'concung.com'
allowed_domains = ['concung.com']
start_urls = ['https://concung.com/']
tracking_url = ''
sitemap_urls = ['https://concung.com/sitemap.xml']
sitemap_rules = [('/[a-zA-Z0-9-]+-\d+\.html$', 'parse_item')]
sitemap_follow = ['']
rules = [
    Rule(LinkExtractor(allow=['-[^(101)]\d+\.html$']), 'parse_item'),
    Rule(LinkExtractor(allow=['-101\d+\.html$']), 'parse'),
    #Rule(LinkExtractor(), 'parse_item_and_links'),
]
