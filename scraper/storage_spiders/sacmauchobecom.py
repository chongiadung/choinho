# Auto generated by generator.py. Delete this line if you make modification.
from scrapy.spiders import Rule
from scrapy.linkextractors import LinkExtractor

XPATH = {
    'name' : "//div[@class='pdhme']/div[@class='product-description']/div[@class='pd-name']/h1[@id='config_name']",
    'price' : "//div[@class='product-description']/div[@class='pctemp']/div[@class='chudam']/span",
    'category' : "//div[@id='breadcrumb']/div/a/span",
    'description' : "//div[@class='pcdetails']/div[@class='tabus'][1]",
    'images' : "//a[@id='Zoomer']/@href | //div[@class='MagicZoomPup']/img/@src",
    'canonical' : "//link[@rel='canonical']/@href",
    'base_url' : "",
    'brand' : ""
}
name = 'sacmauchobe.com'
allowed_domains = ['sacmauchobe.com']
start_urls = ['http://www.sacmauchobe.com']
tracking_url = ''
sitemap_urls = ['']
sitemap_rules = [('', 'parse_item')]
sitemap_follow = []
rules = [
    Rule(LinkExtractor(allow=['/p+\d+\.html$']), 'parse_item'),
    Rule(LinkExtractor(allow=['/c+\d+\.html($|\?page=\d+$)'], deny=['filter=']), 'parse'),
    #Rule(LinkExtractor(), 'parse_item_and_links'),
]
