# Auto generated by generator.py. Delete this line if you make modification.
from scrapy.spiders import Rule
from scrapy.linkextractors import LinkExtractor

XPATH = {
    'name' : "//div[@id='content2']/div/div/table/tbody/tr/td/table/tbody/tr/td/table/tbody/tr/td/b/span[@class='news_title']",
    'price' : "//div[@id='content2']/div/div/table/tbody/tr/td/table/tbody/tr/td/table/tbody/tr/td/span[@class='price']",
    'category' : "//div[@class='text_product']/a",
    'description' : "//div[@id='content2']/div/div/table/tbody/tr/td/table/tbody/tr/td/div[1]",
    'images' : "//div[@id='content2']/div/div/table/tbody/tr/td/div/a/img/@src",
    'canonical' : "",
    'base_url' : "",
    'brand' : ""
}
name = 'baodadienthoai.net'
allowed_domains = ['baodadienthoai.net']
start_urls = ['http://baodadienthoai.net/']
tracking_url = ''
sitemap_urls = ['']
sitemap_rules = [('', 'parse_item')]
sitemap_follow = []
rules = [
    Rule(LinkExtractor(allow = ['-p$','-a+$']), 'parse_item'),
    Rule(LinkExtractor(allow=['-[h|b]($|\?curPg=\d+)']), 'parse'),
    #Rule(LinkExtractor(), 'parse_item_and_links'),
]
