# Auto generated by generator.py. Delete this line if you make modification.
from scrapy.spiders import Rule
from scrapy.linkextractors import LinkExtractor

XPATH = {
    'name' : "/html/body/div[@id='container_body']/div/div[@class='node_content']/div[@class='productDetail']/div[@class='detail-mainInfo']/h1",
    'price' : "/html/body/div[@id='container_body']/div/div[@class='node_content']/div[@class='productDetail']/div[@class='detail-mainInfo']/div[@class='sell_price']/span[@class='uc-price']",
    'category' : "//div[@id='breadcrumb']/span/a/span",
    'description' : "//div[@class='content_details']/div[2]",
    'images' : "/html/body/div[@id='container_body']/div/div[@class='node_content']/div[@class='productDetail']/div[@class='detail-left']/div[@id='images_preview']//a/@href",
    'canonical' : "",
    'base_url' : "",
    'brand' : ""
}
name = 'babylon.vn'
allowed_domains = ['babylon.vn']
start_urls = ['http://www.babylon.vn']
tracking_url = ''
sitemap_urls = ['']
sitemap_rules = [('', 'parse_item')]
sitemap_follow = []
rules = [
    Rule(LinkExtractor(allow=['/[a-zA-Z0-9-]+-\d+\.html$']), 'parse_item'),
    Rule(LinkExtractor(allow=['http://www.babylon.vn/c+\d+/[a-zA-Z0-9-]+\.html($|\?page=\d+$)']), 'parse'),
    #Rule(LinkExtractor(), 'parse_item_and_links'),
]
