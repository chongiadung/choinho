# Auto generated by generator.py. Delete this line if you make modification.
from scrapy.spiders import Rule
from scrapy.linkextractors import LinkExtractor

XPATH = {
    'name' : "//div[@class='list_item']/div[@class='text']/h2/a[@class='name']",
    'price' : "//div[@class='content']/table//tr[1]/td/div[@class='list_item']/div[@class='text']/div/span",
    'category' : "//div[@class='box_center']/div[@class='title']/span/h1",
    'description' : "//div[@class='content']/table//tr[2]/td[@class='product_detail']",
    'images' : "//div[@class='content']/table//tr[1]/td/div[@class='list_item']/div[@class='img']/a/@href",
    'canonical' : "",
    'base_url' : "",
    'brand' : "",
    'in_stock' : "",
    'guarantee' : ""
}
name = 'thaihabooks.com'
allowed_domains = ['thaihabooks.com']
start_urls = ['http://thaihabooks.com']
tracking_url = ''
sitemap_urls = ['']
sitemap_rules = [('', 'parse_item')]
sitemap_follow = ['']
rules = [
    Rule(LinkExtractor(allow=['/sach-thaiha/\d+/']), 'parse_item'),
    Rule(LinkExtractor(allow=['/sach-thaiha/c+\d+/'], deny=['/tin-tuc/','/download/']), 'parse'),
    #Rule(LinkExtractor(), 'parse_item_and_links'),
]
