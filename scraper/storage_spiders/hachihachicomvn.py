# Auto generated by generator.py. Delete this line if you make modification.
from scrapy.spiders import Rule
from scrapy.linkextractors import LinkExtractor

XPATH = {
    'name' : "//div[@class='clear chitietSanPham']/h2",
    'price' : "//p[contains(@class,'Detail')]",
    'category' : "//div[@id='ctl00_ContentPlaceHolder1_pDetailHeader']/h1/a",
    'description' : "//div[@class='scrollHachi']/div[@class='scrollContent']",
    'images' : "//div[@id='thumblist']/div/div/div/a/img/@src",
    'canonical' : "",
    'base_url' : "",
    'brand' : ""
}
name = 'hachihachi.com.vn'
allowed_domains = ['hachihachi.com.vn']
start_urls = ['http://www.hachihachi.com.vn']
tracking_url = ''
sitemap_urls = ['']
sitemap_rules = [('', 'parse_item')]
sitemap_follow = []
rules = [
    Rule(LinkExtractor(allow = ['/[a-z-0-9-]-\d+.aspx$']), 'parse_item'),
    Rule(LinkExtractor(deny = ['Login','Lien-he', 'Chinh-sach-ban-hang', 'Goc-tieu-dung', 'Tin-tuc', 'Gioi-thieu'], allow=['/[a-zA-Z0-9-]+$']), 'parse'),
    #Rule(LinkExtractor(), 'parse_item_and_links'),
]
