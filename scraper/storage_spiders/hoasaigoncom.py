# Auto generated by generator.py. Delete this line if you make modification.
from scrapy.spiders import Rule
from scrapy.linkextractors import LinkExtractor

XPATH = {
    'name' : "//div[@class='container_12']/div[@id='content']/div[@class='product-info']/h1[@class='product-title']",
    'price' : "//div[@class='product-info']/div[@class='right']/div[@class='price']/div[@class='price-data']",
    'category' : "//div[@class='breadcrumb']/span/a/span",
    'description' : "//body/div[@class='container_12']/div[@id='content']/div[@id='tab-description']",
    'images' : "//div[@id='content']/div[@class='product-info']/div[@class='left']/div[@class='image']//img/@src",
    'canonical' : "//link[@rel='canonical']/@href",
    'base_url' : "",
    'brand' : ""
}
name = 'hoasaigon.com'
allowed_domains = ['hoasaigon.com']
start_urls = ['http://www.hoasaigon.com']
tracking_url = ''
sitemap_urls = ['']
sitemap_rules = [('', 'parse_item')]
sitemap_follow = []
rules = [
    Rule(LinkExtractor(allow=['/[a-zA-Z0-9-]+-\d+$']), 'parse_item'),
    Rule(LinkExtractor(allow=['/\.*']), 'parse'),
    #Rule(LinkExtractor(), 'parse_item_and_links'),
]
