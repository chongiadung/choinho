# Auto generated by generator.py. Delete this line if you make modification.
from scrapy.spiders import Rule
from scrapy.linkextractors import LinkExtractor

XPATH = {
    'name' : "//div[@class='content_left']/div[@id='detail_product']/div[@class='title_box_common']/h1[@class='red font13 l']",
    'price' : "//div[@class='float_right_overview']/div[@id='overview_product']/div[@class='overview2']/strong[@class='bg_price red font18']",
    'category' : "//div[@id='wrap']/div[@class='wrap_content']/div[@id='location']/a",
    'description' : "//div[@id='tab_info_detail']/div[@class='content_tab']/div[@id='thongsokythuat']/p",
    'images' : "//div[@id='img_product']/div[@class='zoomp']/a/@href",
    'canonical' : "",
    'base_url' : "",
    'brand' : ""
}
name = 'laptopmax.vn'
allowed_domains = ['laptopmax.vn']
start_urls = ['http://laptopmax.vn']
tracking_url = ''
sitemap_urls = ['']
sitemap_rules = [('', 'parse_item')]
sitemap_follow = []
rules = [
    Rule(LinkExtractor(allow=['/p+\d+\.html']), 'parse_item'),
    Rule(LinkExtractor(allow=['/c+\d+\.html'], deny=['\?']), 'parse'),
    #Rule(LinkExtractor(), 'parse_item_and_links'),
]
